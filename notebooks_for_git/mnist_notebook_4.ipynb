{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Local Adaptive Model - Notebook 4\n",
    "\n",
    "\n",
    "* Prior Probability Shift is one of the common problems encountered in Machine Learning algortihms.   \n",
    "* There are some approaches for dealing with this problem in a 'static' scenario. But there are situations in which we need a model which deals with secvential data as input (e.g. a server which gets input from different users, with different data distributions).   \n",
    "* In this project, we try to build a model which self adapts its predictions based on the local label distribution. \n",
    "\n",
    "### About notebook 4\n",
    "\n",
    "In this notebook we build a testing framework: a data flow for prediction for simulating an online testing scenario; we analyze if the models trained in Notebook3 are able to adapt to local distribution\n",
    "\n",
    "git log --pretty=tformat:'%h %an %ci' --numstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup and data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import Image\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "% matplotlib inline\n",
    "# % matplotlib notebook\n",
    "\n",
    "# %matplotlib qt\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "plt.rcParams['animation.ffmpeg_path'] = 'C:/ffmpeg/bin/ffmpeg.exe'  # used for animation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# os.chdir(r'C:\\Users\\diaco\\Desktop\\ML\\Licenta\\finalproject\\mnist')\n",
    "from dataset import MNISTDataset, Dataset, CIFAR10Dataset\n",
    "import utils\n",
    "from lenet5 import Lenet5\n",
    "from lenet5_with_distr import Lenet5WithDistr\n",
    "import PIL.Image\n",
    "\n",
    "# numpy print options\n",
    "np.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.set_printoptions(precision=3)\n",
    "pd.set_option('display.precision', 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.seed = 112358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_TRAIN_IMG_PATH = 'MNIST_dataset/train-images.idx3-ubyte'\n",
    "MNIST_TRAIN_LABELS_PATH = 'MNIST_dataset/train-labels.idx1-ubyte'\n",
    "MNIST_TEST_IMG_PATH = 'MNIST_dataset/t10k-images.idx3-ubyte'\n",
    "MNIST_TEST_LABELS_PATH = 'MNIST_dataset/t10k-labels.idx1-ubyte'\n",
    "\n",
    "mnist_ds = MNISTDataset(MNIST_TRAIN_IMG_PATH, MNIST_TRAIN_LABELS_PATH, MNIST_TEST_IMG_PATH, MNIST_TEST_LABELS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_DATASET_DIR = './cifar10_dataset/cifar-10-batches-py'\n",
    "cifar10_ds = CIFAR10Dataset(CIFAR10_DATASET_DIR)\n",
    "print(cifar10_ds.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_distributions(test_model, test_ds, train_distr):\n",
    "    test_loss, test_acc, total_predict, total_actual, wrong_predict_images, total_softmax_output_probs = test_model.test_data(test_ds, use_only_one_batch=True)\n",
    "\n",
    "#     print('test_loss = {:.4f}, test_acc = {:.1f}% ({}/{})'.format(test_loss, test_acc * 100, mnist_subset.test.num_examples - len(wrong_predict_images), mnist_subset.test.num_examples))\n",
    "    \n",
    "    # sort wrong_predict_images by target label\n",
    "    correct_predict = total_predict[total_actual == total_predict]\n",
    "    wrong_predict = total_predict[total_actual != total_predict]\n",
    "    wrong_predict_softmax_output_probs = total_softmax_output_probs[total_actual != total_predict]\n",
    "    wrong_actual = total_actual[total_actual != total_predict]\n",
    "    wrong_predict_images = np.array(wrong_predict_images)\n",
    "    wrong_predict_images_sorted = wrong_predict_images[wrong_actual.argsort(), ]\n",
    "    wrong_predict_images_sorted = [image for image in wrong_predict_images_sorted]\n",
    "\n",
    "    count_figures = 6\n",
    "    fig = plt.figure(figsize=(30, 3))\n",
    "    fig.suptitle(y = 1.1, t = 'test_acc = {:.1f}% ({}/{})'.format(test_acc * 100, test_ds.num_examples - len(wrong_predict_images), test_ds.num_examples), fontsize=18, fontweight='bold')\n",
    "\n",
    "    k = 1\n",
    "    plt.subplot(1,count_figures, k)\n",
    "    plt.bar(range(10), train_distr)\n",
    "    plt.xticks(range(0, 10))\n",
    "    plt.title('train label distr')\n",
    "    \n",
    "    k+=1\n",
    "    plt.subplot(1,count_figures, k)\n",
    "    plt.bar(range(10), test_ds.label_distr)\n",
    "    plt.xticks(range(0, 10))\n",
    "    plt.title('test label distr')\n",
    "\n",
    "    k+=1\n",
    "    plt.subplot(1,count_figures, k)\n",
    "    plt.hist(correct_predict, bins=np.arange(11), rwidth=0.8, normed=False)\n",
    "    plt.xticks(range(0, 10))\n",
    "    plt.title('correct predicted label distr')\n",
    "    \n",
    "    k+=1\n",
    "    plt.subplot(1,count_figures, k)\n",
    "    plt.hist(wrong_predict, bins=np.arange(11), rwidth=0.8, normed=False)\n",
    "    plt.xticks(range(0, 10))\n",
    "    plt.title('wrong predicted label distr')\n",
    "    \n",
    "    k+=1\n",
    "    plt.subplot(1,count_figures, k)\n",
    "    plt.hist(wrong_actual, bins=np.arange(11), rwidth=0.8, normed=False)\n",
    "    plt.xticks(range(0, 10))\n",
    "    plt.title('wrong actual label distr')\n",
    "    \n",
    "    k+=1\n",
    "    plt.subplot(1,count_figures, k)\n",
    "    plt.bar(range(0, 10), np.average(wrong_predict_softmax_output_probs, axis=0))\n",
    "    plt.xticks(range(0, 10))\n",
    "    plt.title('wrong predicted: avg. of softmax output probs.')\n",
    "\n",
    "#     plt.savefig(os.path.join(ckpt_dir, plot_filename))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a color list which will be later used for seq. of distributions plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T10_palette_rgb = []\n",
    "T10_palette_rgb_normed = []\n",
    "\n",
    "def hex2rgb(rgb):\n",
    "    temp = rgb.lstrip('#')\n",
    "    return tuple(int(temp[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def hex2rgb_normed(rgb):\n",
    "    temp = rgb.lstrip('#')\n",
    "    return tuple(int(temp[i:i+2], 16)/255.0 for i in (0, 2, 4))\n",
    "\n",
    "x = np.arange(10)\n",
    "y = np.arange(10)\n",
    "for i in range(10):\n",
    "    p = plt.plot(x,y*i, linewidth=5)\n",
    "    T10_palette_rgb.append(hex2rgb(p[0].get_color()))\n",
    "    T10_palette_rgb_normed.append(hex2rgb_normed(p[0].get_color()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1 - testing using a list of distributions and a corresponding list of how many data to generate from each, sequentially\n",
    "## Use Bayesian output probabilities adjusting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a list of distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - use those from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distrs_used_for_training = []\n",
    "\n",
    "# uniform distribution\n",
    "distr = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "# normal distribution centered about label 4-5\n",
    "r = 2\n",
    "distr = [r**1,r**2,r**3,r**4,r**5,r**5,r**4,r**3,r**2,r**1]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "# skewed normal distribution centered about 2\n",
    "distr = [r**3,r**4,r**5,r**4.5,r**4,r**3.5,r**3,r**2.5,r**2,r**1.5]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "# skwed normal distribution centered about 7\n",
    "distr = [r**1.5,r**2,r**2.5,r**3,r**3.5,r**4,r**4.5,r**5,r**4,r**3]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "# bimodal normal distribution\n",
    "distr = [r**1,r**2,r**3,r**2,r**1,r**1,r**2,r**3,r**2,r**1]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "# bimodal skewed normal distribution\n",
    "distr = [r**3.5,r**4,r**3,r**2,r**1,r**1,r**2,r**3,r**4,r**3.5]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "\n",
    "# exponential distribution\n",
    "r=1.4\n",
    "distr = [r**1,r**2,r**3,r**4,r**5,r**6,r**7,r**8,r**9,r**10]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "# exponential distribution\n",
    "r=1.4\n",
    "distr = [r**10,r**9,r**8,r**7,r**6,r**5,r**4,r**3,r**2,r**1]\n",
    "distrs_used_for_training.append(distr/np.sum(distr))\n",
    "\n",
    "print('#distributions used for training = {}'.format(len(distrs_used_for_training)))\n",
    "for idx, distr in enumerate(distrs_used_for_training):\n",
    "    print('idx = {}: distr = {}'.format(idx,distr))\n",
    "#     plt.bar(range(10), distr)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - the special case when data is ordered by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distrs_used_for_training = []\n",
    "\n",
    "for k in range(10):\n",
    "    distr = np.zeros(10)\n",
    "    distr[k] = 1\n",
    "    distrs_used_for_training.append(distr)\n",
    "\n",
    "print('#distributions used for training = {}'.format(len(distrs_used_for_training)))\n",
    "for idx, distr in enumerate(distrs_used_for_training):\n",
    "    print('idx = {}: distr = {}'.format(idx,distr))\n",
    "#     plt.bar(range(10), distr)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - build a sequence of random distributions, using Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distrs_used_for_training = []\n",
    "no_distrs_to_generate = 25\n",
    "# scale_factor_for_Dirichlet = 1.e-1\n",
    "scale_factor_for_Dirichlet = 1.0\n",
    "# scale_factor_for_Dirichlet = 1.e+1\n",
    "shift_factor = 20 # in percents\n",
    "\n",
    "step = int(shift_factor * no_distrs_to_generate / 100)\n",
    "print(step)\n",
    "for k in range(0,no_distrs_to_generate,step):\n",
    "    dirichlet_params = scale_factor_for_Dirichlet * np.random.randint(1,10, 10 , dtype=np.int64)\n",
    "    distrs_used_for_training += list((np.random.dirichlet(dirichlet_params, step)))\n",
    "if len(distrs_used_for_training) < no_distrs_to_generate:\n",
    "    dirichlet_params = scale_factor_for_Dirichlet * np.random.randint(1,10,10, dtype=np.int64)\n",
    "    distrs_used_for_training += list(np.random.dirichlet(dirichlet_params, no_distrs_to_generate - len(distrs_used_for_training)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the sequence of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence_of_images_length = len(distrs_used_for_training)\n",
    "INPUT_DISTR_LIST = distrs_used_for_training\n",
    "NO_EXAMPLES_TO_EXTRACT_FROM_EACH_DISTR = 10\n",
    "list_no_examples_from_each_distr = np.full(len(INPUT_DISTR_LIST), fill_value=NO_EXAMPLES_TO_EXTRACT_FROM_EACH_DISTR)\n",
    "\n",
    "sequence_of_images_length = np.sum(list_no_examples_from_each_distr)\n",
    "sequence_of_imposed_distributions = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "\n",
    "next_pos_to_write = 0\n",
    "for id_distr, distr in enumerate(INPUT_DISTR_LIST):\n",
    "    current_no_examples_to_extract = list_no_examples_from_each_distr[id_distr]\n",
    "#     print('Current input distr. {:3d}                  = {}'.format(id_distr, distr))\n",
    "    sequence_of_imposed_distributions[next_pos_to_write: next_pos_to_write + current_no_examples_to_extract] = distr\n",
    "    next_pos_to_write += current_no_examples_to_extract\n",
    "\n",
    "list_no_examples_from_each_distr = np.full(len(INPUT_DISTR_LIST), fill_value=NO_EXAMPLES_TO_EXTRACT_FROM_EACH_DISTR)\n",
    "figtitle = 'Sequence of imposed distributions (seq_length = {})'.format(sequence_of_images_length)\n",
    "plt.figure(figsize=(80,5))\n",
    "plt.imshow(utils.distr_sequence_to_rgb_image(T10_palette_rgb, sequence_of_imposed_distributions, width=300))\n",
    "plt.savefig('test-{}.png'.format(utils.now_as_str()), )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some empirical rules for estimating how many data we need for build a histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, distr in enumerate(distrs_used_for_training):\n",
    "    print('idx = {}: distr = {}'.format(idx,distr))\n",
    "    cs = np.cumsum(distr)\n",
    "#     print(cs)\n",
    "    iqr = np.argmax(cs>0.75) - np.argmax(cs>0.25)\n",
    "#     print(iqr)\n",
    "    print('Freedman-Diaconis rule: n={}'.format(int((2*iqr)**3)))\n",
    "    std = np.sqrt(np.sum((np.arange(10) ** 2) * distr) - (np.sum(np.arange(10) * distr))**2)\n",
    "    print('Scott\\'s normal ref. rule: n={}'.format(int((3.5 * std)**3)))\n",
    "    print('Rice rule: n={}'.format((10//2)**3))\n",
    "    print('Sqrt rule: n={}'.format(10 ** 2))\n",
    "    print('Sturges formula: n={}'.format(2**(10-1)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Build a sequence of images w.r.t. a list of distributions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DISTR_LIST = distrs_used_for_training\n",
    "NO_EXAMPLES_TO_EXTRACT_FROM_EACH_DISTR = 500\n",
    "list_no_examples_from_each_distr = np.full(len(INPUT_DISTR_LIST), fill_value=NO_EXAMPLES_TO_EXTRACT_FROM_EACH_DISTR)\n",
    "print(list_no_examples_from_each_distr)\n",
    "\n",
    "# build a sequence of images which will be used for simulating an online testing\n",
    "sequence_of_images_length = np.sum(list_no_examples_from_each_distr)\n",
    "sequence_of_images_indices = np.empty(sequence_of_images_length, dtype=np.int32)\n",
    "sequence_of_imposed_distributions = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "sequence_of_real_distributions = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "\n",
    "next_pos_to_write = 0\n",
    "for id_distr, distr in enumerate(INPUT_DISTR_LIST):\n",
    "    current_no_examples_to_extract = list_no_examples_from_each_distr[id_distr]\n",
    "    print('Current input distr. {:3d}                  = {}'.format(id_distr, distr))\n",
    "    mnist_ds = MNISTDataset(MNIST_TRAIN_IMG_PATH, MNIST_TRAIN_LABELS_PATH, MNIST_TEST_IMG_PATH, MNIST_TEST_LABELS_PATH)\n",
    "    indices_wrt_distr = utils.get_indices_wrt_distr(labels=np.argmax(mnist_ds.test.labels, axis=1), weights=distr, max_no_examples=current_no_examples_to_extract)\n",
    "    sequence_of_images_indices[next_pos_to_write: next_pos_to_write + current_no_examples_to_extract] = indices_wrt_distr\n",
    "    sequence_of_imposed_distributions[next_pos_to_write: next_pos_to_write + current_no_examples_to_extract] = distr\n",
    "    real_distr = np.bincount(np.argmax(mnist_ds.test.labels[indices_wrt_distr], axis=1), minlength=10) / current_no_examples_to_extract\n",
    "    sequence_of_real_distributions[next_pos_to_write: next_pos_to_write + current_no_examples_to_extract] = real_distr\n",
    "    next_pos_to_write += current_no_examples_to_extract\n",
    "    print('Label distr. after extracted {:3d} examples = {}\\n'.format(current_no_examples_to_extract, real_distr))\n",
    "\n",
    "print(sequence_of_images_indices)\n",
    "\n",
    "# build a Dataset containing the above sequence\n",
    "mnist_ds = MNISTDataset(MNIST_TRAIN_IMG_PATH, MNIST_TRAIN_LABELS_PATH, MNIST_TEST_IMG_PATH, MNIST_TEST_LABELS_PATH)  # use the sequence_indices on the original mnist_ds\n",
    "sequence_test_ds = Dataset(images=mnist_ds.test.images[sequence_of_images_indices], labels=mnist_ds.test.labels[sequence_of_images_indices], num_classes=MNISTDataset.num_classes)\n",
    "print(sequence_test_ds.num_examples) \n",
    "print('Overall distribution: {}'.format(sequence_test_ds.label_distr))\n",
    "print(np.argmax(sequence_test_ds.labels, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** - plot sequence of imposed distributions (those used for generating the sequence of images); just for comparing it with the one based on actual/predicted labels and to analyze transition periods **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figtitle = 'Sequence of imposed distributions (seq_length = {})'.format(sequence_of_images_length)\n",
    "# utils.plot_sequence_of_distr(list_no_examples_from_each_distr, color_list=T10_palette_rgb, distr_sequence=sequence_of_imposed_distributions, method='bar_plot', fig_title=figtitle, window_length=None, save_to_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** - plot sequence of real distributions (those resulting after imposing distributions for generating the sequence of images)  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figtitle = 'Sequence of real distributions (seq_length = {})'.format(sequence_of_images_length)\n",
    "# plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_real_distributions, method='bar_plot', fig_title=figtitle, window_length=None, save_to_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### I. Testing without outputs adjusting\n",
    "#### This model must be trained on the same amount of data as the one used later, for local distribution adapting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WORK_DIR = './results/Lenet5WithDistr_8distr_[]ex_4/1000ex/'\n",
    "# ckpt_file = 'Lenet5_8distrs_distrPos_None_1000examples_50batchSize_45epochs_2018_06_05---12_09.model.ckpt'\n",
    "\n",
    "# WORK_DIR = './results/PriorProbabilityShift_CIFAR10_2018_06_18---04_55/1000ex/'\n",
    "WORK_DIR = './results/PriorProbabilityShift_experiment_D1_2018_06_10---01_30/1000ex/'\n",
    "ckpt_files = utils.get_all_files_from_dir_ending_with(WORK_DIR, \"ckpt.meta\", without_file_extension=True)\n",
    "ckpt_file = ckpt_files[7]\n",
    "\n",
    "# DATASET_NAME = 'CIFAR10'\n",
    "DATASET_NAME = 'MNIST'\n",
    "\n",
    "def read_dataset(dataset_name):\n",
    "    if dataset_name == 'MNIST':\n",
    "        return MNISTDataset(MNIST_TRAIN_IMG_PATH, MNIST_TRAIN_LABELS_PATH, MNIST_TEST_IMG_PATH, MNIST_TEST_LABELS_PATH)\n",
    "    else:\n",
    "        return CIFAR10Dataset(CIFAR10_DATASET_DIR)\n",
    "\n",
    "ds = read_dataset(DATASET_NAME)\n",
    "restored_distr_pos = utils.restore_variable_from_checkpoint(ckpt_dir=WORK_DIR, ckpt_file=ckpt_file, var_name='distr_pos')\n",
    "current_model_train_distr = utils.restore_variable_from_checkpoint(ckpt_dir=WORK_DIR, ckpt_file=ckpt_file, var_name='train_distr')\n",
    "current_model_test_distr = utils.restore_variable_from_checkpoint(ckpt_dir=WORK_DIR, ckpt_file=ckpt_file, var_name='test_distr')\n",
    "train_num_examples = utils.restore_variable_from_checkpoint(ckpt_dir=WORK_DIR, ckpt_file=ckpt_file, var_name='train_num_examples')\n",
    "test_model = Lenet5WithDistr(dataset=ds, verbose=False, distr_pos=restored_distr_pos)\n",
    "test_model.restore_session(ckpt_dir=WORK_DIR, ckpt_filename=ckpt_file)\n",
    "\n",
    "print('Testing model on the entire sequence, without adapting to local distribution')\n",
    "# print(np.argmax(sequence_test_ds.labels, axis=1))\n",
    "\n",
    "ds = read_dataset(DATASET_NAME)\n",
    "sequence_test_ds = Dataset(images=ds.test.images[sequence_of_images_indices], labels=ds.test.labels[sequence_of_images_indices], num_classes=MNISTDataset.num_classes)\n",
    "\n",
    "test_loss, test_acc, total_predict, total_actual, wrong_predict_images, output_probs = test_model.test_data(sequence_test_ds, use_only_one_batch=True)\n",
    "# print(np.argmax(sequence_test_ds.labels, axis=1))\n",
    "\n",
    "sequence_of_predicted_labels = total_predict\n",
    "sequence_of_output_probs = output_probs\n",
    "sequence_of_actual_labels =  total_actual\n",
    "acc_with_no_adj = test_acc\n",
    "num_correct_predictions_with_no_adj = sequence_test_ds.num_examples - len(wrong_predict_images)\n",
    "\n",
    "plot_results_distributions(test_model=test_model, test_ds=sequence_test_ds, train_distr=current_model_train_distr)\n",
    "\n",
    "print('Accuracy with no ajusting: {:.3f}% ({}/{})'.format(acc_with_no_adj * 100, num_correct_predictions_with_no_adj, sequence_of_images_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### II a. Adjusting the output probabilities using the Bayesian rule - always estimating priors using the original model's predictions\n",
    "#### Build the confusion matrix and show how it is used for prior estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(total_actual, total_predict, labels=range(0, mnist_ds.num_classes))\n",
    "counts_per_class = cm.sum(axis=1)\n",
    "counts_per_class[counts_per_class == 0] = 1  # in order to prevent division by zero\n",
    "cm_normalized = cm.astype('float') / counts_per_class[:, np.newaxis]\n",
    "\n",
    "predicted_label_frequencies = np.bincount(sequence_of_predicted_labels, minlength=10) / sequence_of_images_length\n",
    "real_priors = np.bincount(sequence_of_actual_labels, minlength=10) / sequence_of_images_length\n",
    "estimated_priors, _ ,_ ,_ = np.linalg.lstsq(cm_normalized.T, predicted_label_frequencies, rcond=None)  # use lstsq instead of solve to prevent the case of singular matrices\n",
    "\n",
    "uniform_distr = np.full(shape = (10), fill_value=0.1, dtype=np.float32)\n",
    "estimated_priord_for_uniform_distr, _ ,_ ,_ = np.linalg.lstsq(cm_normalized.T, uniform_distr, rcond=None)  # use lstsq instead of solve to prevent the case of singular matrices\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.suptitle(y = 1.1, t = 'Priors estimation using confusion matrix', fontsize=18, fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(10), current_model_train_distr)\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title('train label distr.', fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(10), real_priors)\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title('test label distr. (real priors)', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(10), predicted_label_frequencies)\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title('predicted label distr.', fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(10), estimated_priors)\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title('estimated priors', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(10), np.abs(estimated_priord_for_uniform_distr))\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title('estimated priors for uniform distr.', fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Build and plot the sequences of distributions which will be used in the adjusting operation\n",
    " 1. adjusting using real priors: use what the model should predict, from the future; this case should give the best accuracy\n",
    " 2. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past)\n",
    " 3. adjusting using estimated priors by the recent predicted labels (what the model predicted in the recent past)\n",
    " 4. adjusting using estimated priors by the recent predicted labels (what the model predicted in the recent past); estimate using confusion matrix method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "# build the sequence of distributions in order to maximize the correlation between them and the impose distribution\n",
    "WINDOW_LENGTH = 100\n",
    "\n",
    "def L1_distance(distr1, distr2):\n",
    "    return np.sum(np.abs(distr1 - distr2))  # L1 distance\n",
    "def corr_coeff_distance(distr1, distr2):\n",
    "    return 1 - np.corrcoef(distr1, distr2)[0][1]\n",
    "def cosine_distance(distr1, distr2):\n",
    "    return (1 - np.sum(distr1 * distr2) / np.sqrt(np.sum(distr1 * distr1) * np.sum(distr2 * distr2)))\n",
    "\n",
    "# distance_measure_function = L1_distance\n",
    "# distance_thr = 0.38 # L1 distance should be greater than distance_thr to decide that there is a changepoint\n",
    "\n",
    "# distance_measure_function = corr_coeff_distance\n",
    "# distance_thr = 0.85 # correlation coefficient should be less than distance_thr to decide that there is a changepoint\n",
    "\n",
    "distance_measure_function = cosine_distance\n",
    "distance_thr = 0.05 # correlation coefficient should be less than distance_thr to decide that there is a changepoint\n",
    "\n",
    "sequence_of_distributions_based_on_actual_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "adapted_sequence_of_distributions_based_on_actual_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "# adapted_sequence_of_distributions_based_on_predicted_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "# adapted_sequence_of_distributions_based_on_predicted_labels_and_cm = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "3\n",
    "distances_between_distrs = np.empty(sequence_of_images_length)\n",
    "start_point_of_current_extended_window = 0\n",
    "\n",
    "for k in range(len(sequence_of_images_indices)):\n",
    "    if k == 0:\n",
    "        sequence_of_distributions_based_on_actual_labels[k, :] = uniform_distr\n",
    "        adapted_sequence_of_distributions_based_on_actual_labels[k, :] = uniform_distr\n",
    "    elif k < WINDOW_LENGTH:\n",
    "        sequence_of_distributions_based_on_actual_labels[k, :] = np.bincount(sequence_of_actual_labels[0:k], minlength=10) / k\n",
    "        adapted_sequence_of_distributions_based_on_actual_labels[k, :] = sequence_of_distributions_based_on_actual_labels[k, :]\n",
    "    else:\n",
    "        sequence_of_distributions_based_on_actual_labels[k, :] = np.bincount(sequence_of_actual_labels[k - WINDOW_LENGTH:k], minlength=10) / WINDOW_LENGTH\n",
    "        current_window_distr = np.bincount(sequence_of_actual_labels[k - WINDOW_LENGTH:k], minlength=10) / WINDOW_LENGTH\n",
    "        current_imposed_distr = adapted_sequence_of_distributions_based_on_actual_labels[k-1]\n",
    "        dist = distance_measure_function(current_imposed_distr, current_window_distr)\n",
    "\n",
    "        if dist > distance_thr:\n",
    "            start_point_of_current_extended_window = k - WINDOW_LENGTH\n",
    "        adapted_sequence_of_distributions_based_on_actual_labels[k, :] = np.bincount(sequence_of_actual_labels[start_point_of_current_extended_window:k], minlength=10) / (k - start_point_of_current_extended_window)\n",
    "    distances_between_distrs[k] = distance_measure_function(sequence_of_imposed_distributions[k], sequence_of_distributions_based_on_actual_labels[k])\n",
    "\n",
    "print((time.time() - ts) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the sequence of distribution\n",
    "figtitle = 'Sequence of imposed distributions (seq_length = {})'.format(sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_imposed_distributions, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=None, save_to_file=False)\n",
    "\n",
    "figtitle = 'Sequence of distributions based on actual labels (window_length = {}, seq_length = {})'.format(WINDOW_LENGTH, sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_distributions_based_on_actual_labels, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=WINDOW_LENGTH, save_to_file=False)\n",
    "\n",
    "\n",
    "figtitle = 'Adapted sequence of distributions based on actual labels (window_length = {}, seq_length = {})'.format(WINDOW_LENGTH, sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=adapted_sequence_of_distributions_based_on_actual_labels, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=WINDOW_LENGTH, save_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_actual_labels.flat)[0][1]\n",
    "print('corrcoef(sequence_of_imposed_distributions, sequence_of_distributions_based_on_actual_labels)                                                = {:.5f}'.format(corr_coeff))\n",
    "corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, adapted_sequence_of_distributions_based_on_actual_labels.flat)[0][1]\n",
    "print('corrcoef(sequence_of_imposed_distributions, adapted_sequence_of_distributions_based_on_actual_labels)                                        = {:.5f}'.format(corr_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_priors = current_model_train_distr\n",
    "uniform_distr = np.full(shape = (10), fill_value=0.1, dtype=np.float32)\n",
    "\n",
    "DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES = True\n",
    "distr_to_assume_for_the_first_window_length_images=uniform_distr\n",
    "\n",
    "# 1. adjusting using real priors: use what the model should predict, from the future; this case should give the best accuracy \n",
    "real_priors = sequence_of_real_distributions\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_real_priors = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "# 2. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past)\n",
    "real_priors = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "    real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "    real_priors[WINDOW_LENGTH:] = sequence_of_distributions_based_on_actual_labels[WINDOW_LENGTH:]\n",
    "else:\n",
    "    real_priors = sequence_of_distributions_based_on_actual_labels\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_estimated_priors_from_recent_actual_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "# 3. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past), with adaptatation for stability\n",
    "if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "    real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "    real_priors[WINDOW_LENGTH:] = adapted_sequence_of_distributions_based_on_actual_labels[WINDOW_LENGTH:]\n",
    "else:\n",
    "    real_priors = sequence_of_distributions_based_on_predicted_labels\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "adapted_preds_with_adj_using_estimated_priors_from_recent_actual_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "    \n",
    "print('Accuracy with no ajusting:                                                                  {:.3f}% ({}/{})'.format(acc_with_no_adj * 100, num_correct_predictions_with_no_adj, sequence_of_images_length))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_real_priors)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using real priors:                                                   {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_actual_labels)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using estimated priors from recent actual labels:                    {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == adapted_preds_with_adj_using_estimated_priors_from_recent_actual_labels)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using estimated priors from recent actual labels and adapting:       {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WINDOW_LENGTH=100\n",
    "\n",
    "corr_coeff_between_real_distr_and_adapted_estimates_list = []\n",
    "acc_list = []\n",
    "\n",
    "# distance_measure_function = L1_distance\n",
    "# distance_thr = 0.38 # L1 distance should be greater than distance_thr to decide that there is a changepoint\n",
    "\n",
    "# distance_measure_function = corr_coeff_distance\n",
    "# distance_thr = 0.85 # correlation coefficient should be less than distance_thr to decide that there is a changepoint\n",
    "\n",
    "distance_measure_function = cosine_distance\n",
    "distance_thr = 0.05 # correlation coefficient should be less than distance_thr to decide that there is a changepoint\n",
    "\n",
    "for distance_thr in np.arange(0, 2.01, 0.05):\n",
    "    distance_thr = 0.05\n",
    "    print(distance_thr)\n",
    "    sequence_of_distributions_based_on_actual_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    adapted_sequence_of_distributions_based_on_actual_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    # adapted_sequence_of_distributions_based_on_predicted_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    # adapted_sequence_of_distributions_based_on_predicted_labels_and_cm = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "\n",
    "    distances_between_distrs = np.empty(sequence_of_images_length)\n",
    "    start_point_of_current_extended_window = 0\n",
    "\n",
    "    for k in range(len(sequence_of_images_indices)):\n",
    "        if k == 0:\n",
    "            sequence_of_distributions_based_on_actual_labels[k, :] = uniform_distr\n",
    "            adapted_sequence_of_distributions_based_on_actual_labels[k, :] = uniform_distr\n",
    "        elif k < WINDOW_LENGTH:\n",
    "            sequence_of_distributions_based_on_actual_labels[k, :] = np.bincount(sequence_of_actual_labels[0:k], minlength=10) / k\n",
    "            adapted_sequence_of_distributions_based_on_actual_labels[k, :] = sequence_of_distributions_based_on_actual_labels[k, :]\n",
    "        else:\n",
    "            sequence_of_distributions_based_on_actual_labels[k, :] = np.bincount(sequence_of_actual_labels[k - WINDOW_LENGTH:k], minlength=10) / WINDOW_LENGTH\n",
    "            current_window_distr = np.bincount(sequence_of_actual_labels[k - WINDOW_LENGTH:k], minlength=10) / WINDOW_LENGTH\n",
    "            current_imposed_distr = adapted_sequence_of_distributions_based_on_actual_labels[k-1]\n",
    "            dist = distance_measure_function(current_imposed_distr, current_window_distr)\n",
    "            if dist > distance_thr:\n",
    "                start_point_of_current_extended_window = k - WINDOW_LENGTH\n",
    "            adapted_sequence_of_distributions_based_on_actual_labels[k, :] = np.bincount(sequence_of_actual_labels[start_point_of_current_extended_window:k], minlength=10) / (k - start_point_of_current_extended_window)\n",
    "    #     distances_between_distrs[k] = np.corrcoef(sequence_of_imposed_distributions[k], sequence_of_distributions_based_on_actual_labels[k])[0][1]\n",
    "    #     corr_coeffs2[k] = np.corrcoef(sequence_of_imposed_distributions[k], adapted_sequence_of_distributions_based_on_actual_labels[k])[0][1]\n",
    "        distances_between_distrs[k] = distance_measure_function(sequence_of_imposed_distributions[k], sequence_of_distributions_based_on_actual_labels[k])\n",
    "        \n",
    "        \n",
    "    corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_actual_labels.flat)[0][1]\n",
    "    print('corrcoef(sequence_of_imposed_distributions, sequence_of_distributions_based_on_actual_labels)                                                = {:.5f}'.format(corr_coeff))\n",
    "    corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, adapted_sequence_of_distributions_based_on_actual_labels.flat)[0][1]\n",
    "    print('corrcoef(sequence_of_imposed_distributions, adapted_sequence_of_distributions_based_on_actual_labels)                                        = {:.5f}'.format(corr_coeff))\n",
    "    \n",
    "    corr_coeff_between_real_distr_and_adapted_estimates_list.append(corr_coeff)\n",
    "    \n",
    "    old_priors = current_model_train_distr\n",
    "    uniform_distr = np.full(shape = (10), fill_value=0.1, dtype=np.float32)\n",
    "\n",
    "    DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES = True\n",
    "    distr_to_assume_for_the_first_window_length_images=uniform_distr\n",
    "\n",
    "    # 1. adjusting using real priors: use what the model should predict, from the future; this case should give the best accuracy \n",
    "    real_priors = sequence_of_real_distributions\n",
    "    initial_output_probs = sequence_of_output_probs\n",
    "    adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "    preds_with_adj_using_real_priors = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "    # 2. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past)\n",
    "    real_priors = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "        real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "        real_priors[WINDOW_LENGTH:] = sequence_of_distributions_based_on_actual_labels[WINDOW_LENGTH:]\n",
    "    else:\n",
    "        real_priors = sequence_of_distributions_based_on_actual_labels\n",
    "    initial_output_probs = sequence_of_output_probs\n",
    "    adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "    preds_with_adj_using_estimated_priors_from_recent_actual_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "    # 3. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past), with adaptatation for stability\n",
    "    if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "        real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "        real_priors[WINDOW_LENGTH:] = adapted_sequence_of_distributions_based_on_actual_labels[WINDOW_LENGTH:]\n",
    "    else:\n",
    "        real_priors = sequence_of_distributions_based_on_predicted_labels\n",
    "    initial_output_probs = sequence_of_output_probs\n",
    "    adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "    adapted_preds_with_adj_using_estimated_priors_from_recent_actual_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "\n",
    "    print('Accuracy with no ajusting:                                                                  {:.3f}% ({}/{})'.format(acc_with_no_adj * 100, num_correct_predictions_with_no_adj, sequence_of_images_length))\n",
    "\n",
    "    num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_real_priors)\n",
    "    acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "    print('Accuracy with ajusting using real priors:                                                   {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "    print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "    num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_actual_labels)\n",
    "    acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "    print('Accuracy with ajusting using estimated priors from recent actual labels:                    {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "    print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "    num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == adapted_preds_with_adj_using_estimated_priors_from_recent_actual_labels)\n",
    "    acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "    print('Accuracy with ajusting using estimated priors from recent actual labels and adapting:       {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "    print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "    \n",
    "    acc_list.append(acc_with_adj)\n",
    "    \n",
    "    print('\\n\\n\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(acc_list, linewidth=3, label='accuracy')\n",
    "plt.xticks(np.arange(len(acc_list)), np.round(np.arange(0, 2, 0.05), decimals=2))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(corr_coeff_between_real_distr_and_adapted_estimates_list, linewidth=3, label='corr(imposed, adapted actual)')\n",
    "plt.xticks(np.arange(len(acc_list)), np.round(np.arange(0, 2, 0.05), decimals=2))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the sequence of distribution\n",
    "figtitle = 'Sequence of imposed distributions (seq_length = {})'.format(sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_imposed_distributions, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=None, save_to_file=True)\n",
    "\n",
    "figtitle = 'Sequence of distributions based on actual labels (window_length = {}, seq_length = {})'.format(WINDOW_LENGTH, sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_distributions_based_on_actual_labels, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=WINDOW_LENGTH, save_to_file=True)\n",
    "\n",
    "figtitle = 'Sequence of distributions based on predicted labels (window_length = {}, seq_length = {})'.format(WINDOW_LENGTH, sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_distributions_based_on_predicted_labels, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=WINDOW_LENGTH, save_to_file=True)\n",
    "\n",
    "figtitle = 'Sequence of distributions based on predicted labels and confusion matrix (window_length = {}, seq_length = {})'.format(WINDOW_LENGTH, sequence_of_images_length)\n",
    "utils.plot_sequence_of_distr(list_no_examples_from_each_distr, distr_sequence=sequence_of_distributions_based_on_predicted_labels_and_cm, \n",
    "                             method='my_distr_img_plot', fig_title=figtitle, color_list=T10_palette_rgb, window_length=WINDOW_LENGTH, save_to_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "old_priors = current_model_train_distr\n",
    "uniform_distr = np.full(shape = (10), fill_value=0.1, dtype=np.float32)\n",
    "\n",
    "DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES = True\n",
    "distr_to_assume_for_the_first_window_length_images=uniform_distr\n",
    "\n",
    "# 1. adjusting using real priors: use what the model should predict, from the future; this case should give the best accuracy \n",
    "real_priors = sequence_of_real_distributions\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_real_priors = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "# 1'. adjusting using overall distribution as priors\n",
    "real_priors = sequence_test_ds.label_distr\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_overall_distr = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "# 2. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past)\n",
    "real_priors = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "    real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "    real_priors[WINDOW_LENGTH:] = sequence_of_distributions_based_on_actual_labels[WINDOW_LENGTH:]\n",
    "else:\n",
    "    real_priors = sequence_of_distributions_based_on_actual_labels\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_estimated_priors_from_recent_actual_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "# 3. adjusting using estimated priors by the recent predicted labels (what the model predicted in the recent past)\n",
    "if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "    real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "    real_priors[WINDOW_LENGTH:] = sequence_of_distributions_based_on_predicted_labels[WINDOW_LENGTH:]\n",
    "else:\n",
    "    real_priors = sequence_of_distributions_based_on_predicted_labels\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_estimated_priors_from_recent_predicted_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "# 4. adjusting using estimated priors by the recent predicted labels (what the model predicted in the recent past) and confusion matrix method\n",
    "if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "    real_priors[:WINDOW_LENGTH] = distr_to_assume_for_the_first_window_length_images\n",
    "    real_priors[WINDOW_LENGTH:] = sequence_of_distributions_based_on_predicted_labels_and_cm[WINDOW_LENGTH:]\n",
    "else:\n",
    "    real_priors = sequence_of_distributions_based_on_predicted_labels_and_cm\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_estimated_priors_from_recent_predicted_labels_and_cm = np.argmax(adj_output_probs, axis=1)\n",
    "    \n",
    "    \n",
    "print('Accuracy with no ajusting:                                                                  {:.3f}% ({}/{})'.format(acc_with_no_adj * 100, num_correct_predictions_with_no_adj, sequence_of_images_length))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_real_priors)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using real priors:                                                   {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_overall_distr)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using global distribution:                                           {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_actual_labels)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using estimated priors from recent actual labels:                    {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_predicted_labels)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using estimated priors from recent predicted labels:                 {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_predicted_labels_and_cm)\n",
    "acc_with_adj = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "print('Accuracy with ajusting using estimated priors from recent predictions and confusion matrix: {:.3f}% ({}/{})'.format(acc_with_adj * 100, num_correct_predictions_with_adj, sequence_of_images_length))\n",
    "print('Diff = {:.3f}%'.format((acc_with_adj - acc_with_no_adj) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Study the correlation between estimated priors with different window lengths and the accuracy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff = np.corrcoef(sequence_of_distributions_based_on_actual_labels.flat, sequence_of_distributions_based_on_predicted_labels.flat)[0][1]\n",
    "print('corrcoef(sequence_of_distributions_based_on_actual_labels, sequence_of_distributions_based_on_predicted_labels)                      = {:.5f}'.format(corr_coeff))\n",
    "\n",
    "corr_coeff = np.corrcoef(sequence_of_distributions_based_on_actual_labels.flat, sequence_of_distributions_based_on_predicted_labels_and_cm.flat)[0][1]\n",
    "print('corrcoef(sequence_of_distributions_based_on_actual_labels, sequence_of_distributions_based_on_predicted_labels_and_confusion_matrix) = {:.5f}'.format(corr_coeff))\n",
    "\n",
    "corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_actual_labels.flat)[0][1]\n",
    "print('corrcoef(sequence_of_imposed_distributions, sequence_of_distributions_based_on_actual_labels)                                        = {:.5f}'.format(corr_coeff))\n",
    "\n",
    "corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_predicted_labels.flat)[0][1]\n",
    "print('corrcoef(sequence_of_imposed_distributions, sequence_of_distributions_based_on_predicted_labels)                                     = {:.5f}'.format(corr_coeff))\n",
    "\n",
    "corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_predicted_labels_and_cm.flat)[0][1]\n",
    "print('corrcoef(sequence_of_imposed_distributions, sequence_of_distributions_based_on_predicted_labels_and_confusion_matrix)                = {:.5f}'.format(corr_coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WINDOW_LENGTHS = [10, 15, 25, 50, 75, 100, 125, 150, 200, 250]\n",
    "temp = 500\n",
    "while temp < sequence_of_images_length:\n",
    "    WINDOW_LENGTHS.append(temp)\n",
    "    temp *= 2\n",
    "if WINDOW_LENGTHS[-1] != sequence_of_images_length:\n",
    "    WINDOW_LENGTHS.append(sequence_of_images_length)\n",
    "    \n",
    "WINDOW_LENGTHS = [100]\n",
    "\n",
    "print(WINDOW_LENGTHS)\n",
    "\n",
    "DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES = False\n",
    "distr_to_assume_for_the_first_window_length_images=uniform_distr\n",
    "\n",
    "old_priors = current_model_train_distr\n",
    "uniform_distr = np.full(shape = (10), fill_value=0.1, dtype=np.float32)\n",
    "\n",
    "full_results_dict = {}\n",
    "idx_model = 0\n",
    "full_results_dict[ckpt_file] = {'idx_model':idx_model, 'train_distr': current_model_train_distr, 'test_distr': current_model_test_distr, 'train_num_examples': train_num_examples, 'test_seq_length':sequence_of_images_length,\n",
    "                                   'test_results': {'id_test':[], 'method':[], 'window_length':[], 'test_acc':[], 'num_correct_preds':[], 'corr_coeff': []}}\n",
    "id_test = 0\n",
    "\n",
    "def save_test_results_to_dict(test_dict, id_test, method, window_length, num_correct_preds, sequence_of_images_length, corr_coeff):\n",
    "    test_dict['id_test'].append(id_test)\n",
    "    test_dict['method'].append(method)\n",
    "    test_dict['window_length'].append(window_length)\n",
    "    acc = num_correct_predictions_with_adj / sequence_of_images_length\n",
    "    test_dict['test_acc'].append(num_correct_preds / sequence_of_images_length)\n",
    "    test_dict['num_correct_preds'].append(num_correct_preds)\n",
    "    test_dict['corr_coeff'].append(corr_coeff)\n",
    "\n",
    "save_test_results_to_dict(test_dict=full_results_dict[ckpt_file]['test_results'], id_test=id_test, method='no_adj',\n",
    "                          window_length=None, num_correct_preds=num_correct_predictions_with_no_adj, sequence_of_images_length=sequence_of_images_length, corr_coeff=None)\n",
    "\n",
    "# 1. adjusting using real priors: use what the model should predict, from the future; this case should give the best accuracy \n",
    "real_priors = sequence_of_real_distributions\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_real_priors = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_real_priors)\n",
    "corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_real_distributions.flat)[0][1]\n",
    "save_test_results_to_dict(test_dict=full_results_dict[ckpt_file]['test_results'], id_test=id_test, method='adj_using_real_priors',\n",
    "                          window_length=None, num_correct_preds=num_correct_predictions_with_adj, sequence_of_images_length=sequence_of_images_length, corr_coeff=corr_coeff)\n",
    "\n",
    "# 1'. adjusting using overall distribution as priors\n",
    "real_priors = sequence_test_ds.label_distr\n",
    "initial_output_probs = sequence_of_output_probs\n",
    "adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "preds_with_adj_using_overall_distr = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_overall_distr)\n",
    "save_test_results_to_dict(test_dict=full_results_dict[ckpt_file]['test_results'], id_test=id_test, method='adj_using_overall_distr',\n",
    "                          window_length=None, num_correct_preds=num_correct_predictions_with_adj, sequence_of_images_length=sequence_of_images_length, corr_coeff=None)\n",
    "\n",
    "for id_window, window_length in enumerate(WINDOW_LENGTHS):\n",
    "    print('\\rProgress = {:.0f}%'.format((id_window + 1)/len(WINDOW_LENGTHS) * 100), end='')\n",
    "    sequence_of_distributions_based_on_actual_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    sequence_of_distributions_based_on_predicted_labels = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    sequence_of_distributions_based_on_predicted_labels_and_cm = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    \n",
    "    for k in range(sequence_of_images_length):\n",
    "        if k == 0:\n",
    "            sequence_of_distributions_based_on_actual_labels[k] = uniform_distr\n",
    "            sequence_of_distributions_based_on_predicted_labels[k] = uniform_distr\n",
    "        elif k < window_length:\n",
    "            sequence_of_distributions_based_on_actual_labels[k] = np.bincount(sequence_of_actual_labels[0:k], minlength=10) / k\n",
    "            sequence_of_distributions_based_on_predicted_labels[k] = np.bincount(sequence_of_predicted_labels[0:k], minlength=10) / k\n",
    "        else:\n",
    "            sequence_of_distributions_based_on_actual_labels[k] = np.bincount(sequence_of_actual_labels[k - window_length:k], minlength=10) / window_length\n",
    "            sequence_of_distributions_based_on_predicted_labels[k] = np.bincount(sequence_of_predicted_labels[k - window_length:k], minlength=10) / window_length\n",
    "\n",
    "        sequence_of_distributions_based_on_predicted_labels_and_cm[k] = np.linalg.solve(cm_normalized.T, sequence_of_distributions_based_on_predicted_labels[k])\n",
    "        sequence_of_distributions_based_on_predicted_labels_and_cm[k][sequence_of_distributions_based_on_predicted_labels_and_cm[k] < 0] = 0 # if there are negative weights (probably due to numerical precision), make them zero\n",
    "        sequence_of_distributions_based_on_predicted_labels_and_cm[k] /= sum(sequence_of_distributions_based_on_predicted_labels_and_cm[k])  # make it sum to 1\n",
    "        \n",
    "    # 2. adjusting using estimated priors by the recent actual labels (what the model should have predicted in the recent past)\n",
    "    real_priors = np.empty(shape=[sequence_of_images_length, mnist_ds.num_classes])\n",
    "    if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "        real_priors[:window_length] = distr_to_assume_for_the_first_window_length_images\n",
    "        real_priors[window_length:] = sequence_of_distributions_based_on_actual_labels[window_length:]\n",
    "    else:\n",
    "        real_priors = sequence_of_distributions_based_on_actual_labels\n",
    "    initial_output_probs = sequence_of_output_probs\n",
    "    adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "    preds_with_adj_using_estimated_priors_from_recent_actual_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "    # 3. adjusting using estimated priors by the recent predicted labels (what the model predicted in the recent past)\n",
    "    if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "        real_priors[:window_length] = distr_to_assume_for_the_first_window_length_images\n",
    "        real_priors[window_length:] = sequence_of_distributions_based_on_predicted_labels[window_length:]\n",
    "    else:\n",
    "        real_priors = sequence_of_distributions_based_on_predicted_labels\n",
    "    initial_output_probs = sequence_of_output_probs\n",
    "    adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "    preds_with_adj_using_estimated_priors_from_recent_predicted_labels = np.argmax(adj_output_probs, axis=1)\n",
    "\n",
    "    # 4. adjusting using estimated priors by the recent predicted labels (what the model predicted in the recent past) and confusion matrix method\n",
    "    if DONT_ADJUST_FIRST_WINDOW_LENGTH_IMAGES:\n",
    "        real_priors[:window_length] = distr_to_assume_for_the_first_window_length_images\n",
    "        real_priors[window_length:] = sequence_of_distributions_based_on_predicted_labels_and_cm[window_length:]\n",
    "    else:\n",
    "        real_priors = sequence_of_distributions_based_on_predicted_labels_and_cm\n",
    "    initial_output_probs = sequence_of_output_probs\n",
    "    adj_output_probs = (real_priors / old_priors) *  initial_output_probs/ (np.sum((real_priors / old_priors) * initial_output_probs))\n",
    "    preds_with_adj_using_estimated_priors_from_recent_predicted_labels_and_cm = np.argmax(adj_output_probs, axis=1)\n",
    "    \n",
    "    num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_actual_labels)\n",
    "    corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_actual_labels.flat)[0][1]\n",
    "    save_test_results_to_dict(test_dict=full_results_dict[ckpt_file]['test_results'], id_test=id_test, method='adj_using_estimated_priors_from_recent_actual_labels', \n",
    "                              window_length=window_length, num_correct_preds=num_correct_predictions_with_adj, sequence_of_images_length=sequence_of_images_length, corr_coeff=corr_coeff)\n",
    "    \n",
    "    num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_predicted_labels)\n",
    "    corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_predicted_labels.flat)[0][1]\n",
    "    save_test_results_to_dict(test_dict=full_results_dict[ckpt_file]['test_results'], id_test=id_test, method='adj_using_estimated_priors_from_recent_predicted_labels', \n",
    "                              window_length=window_length, num_correct_preds=num_correct_predictions_with_adj, sequence_of_images_length=sequence_of_images_length, corr_coeff=corr_coeff)\n",
    "    \n",
    "    num_correct_predictions_with_adj = np.sum(sequence_of_actual_labels == preds_with_adj_using_estimated_priors_from_recent_predicted_labels_and_cm)\n",
    "    corr_coeff = np.corrcoef(sequence_of_imposed_distributions.flat, sequence_of_distributions_based_on_predicted_labels_and_cm.flat)[0][1]\n",
    "    save_test_results_to_dict(test_dict=full_results_dict[ckpt_file]['test_results'], id_test=id_test, method='adj_using_estimated_priors_from_recent_predicted_labels_and_cm', \n",
    "                              window_length=window_length, num_correct_preds=num_correct_predictions_with_adj, sequence_of_images_length=sequence_of_images_length, corr_coeff=corr_coeff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restored_perf_dict = full_results_dict\n",
    "perf_df = pd.DataFrame(restored_perf_dict[ckpt_file]['test_results'], columns=list(restored_perf_dict[ckpt_file]['test_results'].keys()))\n",
    "display(perf_df.head())\n",
    "temp_df = perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_actual_labels']\n",
    "display(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Accuracy comparison', fontsize=30)\n",
    "\n",
    "bar_width = 0.2\n",
    "line_width = 5\n",
    "y = float(perf_df[perf_df.method == 'no_adj'].test_acc)\n",
    "plt.plot([0, len(temp_df.window_length) - 1], [y, y], '--', linewidth=line_width, alpha=1, label='no adjusting', color=T10_palette_rgb_normed[7])\n",
    "\n",
    "y = float(perf_df[perf_df.method == 'adj_using_real_priors'].test_acc)\n",
    "plt.plot([0, len(temp_df.window_length) - 1], [y, y], '-', linewidth=line_width, alpha=1, label='adjusting using real priors', color=T10_palette_rgb_normed[2])\n",
    "\n",
    "y = float(perf_df[perf_df.method == 'adj_using_overall_distr'].test_acc)\n",
    "plt.plot([0, len(temp_df.window_length) - 1], [y, y], ':', linewidth=line_width, alpha=1, label='adjusting using global distribution', color=T10_palette_rgb_normed[3])\n",
    "\n",
    "y = np.array(perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_actual_labels'].test_acc)\n",
    "# plt.bar(np.arange(len(temp_df.window_length)) - bar_width, y, width=bar_width,  label='adjusting using estimated priors from recent actual labels', color=T10_palette_rgb_normed[0])\n",
    "plt.plot(y, '--', linewidth=3, label='adjusting using estimated priors from recent actual labels', color=T10_palette_rgb_normed[0])\n",
    "\n",
    "y = np.array(perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_predicted_labels'].test_acc)\n",
    "# plt.bar(np.arange(len(temp_df.window_length)), y, width=bar_width,  label='adjusting using estimated priors from recent predicted labels', color=T10_palette_rgb_normed[5])\n",
    "plt.plot(y, ':', linewidth=3, label='adjusting using estimated priors from recent predicted labels', color=T10_palette_rgb_normed[5])\n",
    "\n",
    "y = np.array(perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_predicted_labels_and_cm'].test_acc)\n",
    "# plt.bar(np.arange(len(temp_df.window_length)) + bar_width, y, width=bar_width,  label='adjusting using estimated priors from recent predicted labels and confusion matrix', color=T10_palette_rgb_normed[6])\n",
    "plt.plot(y, '-', linewidth=3, label='adjusting using estimated priors from recent predicted labels and confusion matrix', color=T10_palette_rgb_normed[6])\n",
    "\n",
    "# plt.grid(axis='y')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right', fontsize=20)\n",
    "plt.xlabel('Window length', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "# plt.yticks(np.arange(0, 1.01, 0.1))\n",
    "plt.xticks(np.arange(len(temp_df.window_length)), temp_df.window_length.astype(int))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Correlation coefficient between sequence of imposed priors and real priors', fontsize=30)\n",
    "\n",
    "y = np.array(perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_actual_labels'].corr_coeff)\n",
    "# plt.bar(np.arange(len(temp_df.window_length)) - bar_width, y, width=bar_width,  label='adjusting using estimated priors from recent actual labels', color=T10_palette_rgb_normed[0])\n",
    "plt.plot(y, '--', linewidth=3, label='adjusting using estimated priors from recent actual labels', color=T10_palette_rgb_normed[0])\n",
    "\n",
    "y = np.array(perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_predicted_labels'].corr_coeff)\n",
    "# plt.bar(np.arange(len(temp_df.window_length)), y, width=bar_width,  label='adjusting using estimated priors from recent predicted labels', color=T10_palette_rgb_normed[5])\n",
    "plt.plot(y, ':', linewidth=3, label='adjusting using estimated priors from recent predicted labels', color=T10_palette_rgb_normed[5])\n",
    "\n",
    "y = np.array(perf_df[perf_df.method == 'adj_using_estimated_priors_from_recent_predicted_labels_and_cm'].corr_coeff)\n",
    "# plt.bar(np.arange(len(temp_df.window_length)) + bar_width, y, width=bar_width,  label='adjusting using estimated priors from recent predicted labels and confusion matrix', color=T10_palette_rgb_normed[6])\n",
    "plt.plot(y, '-', linewidth=3, label='adjusting using estimated priors from recent predicted labels and confusion matrix', color=T10_palette_rgb_normed[6])\n",
    "\n",
    "# plt.grid(axis='y')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right', fontsize=20)\n",
    "plt.xlabel('Window length', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "# plt.yticks(np.arange(0, 1.01, 0.1))\n",
    "plt.xticks(np.arange(len(temp_df.window_length)), temp_df.window_length.astype(int))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
